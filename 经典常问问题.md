Q：Inception v1v2v3v4发展与改进  


Q：resnet各个版本  


Q：Mobilenet v1v2v3区别，性能  


Q：Mobilenet v2为什么用relu6  


Q：卷积优化有哪些操作  


Q：轻量级网络  


Q：各种深度学习框架，区别  


Q：二阶检测器，RCNN系列发展，细节，包括损失函数  


Q：一阶检测器，SSD,YOLO发展，细节，包括损失函数  


Q：ancor free了解  


Q：样本不均衡，怎么解决。focal loss,GHM,OHEM  


Q：训练和测试不一样的操作有哪些  


Q：BN，sync bn，merge bn  


Q：pooling反传，CNN反传  


Q：sigmoid缺点，sigmoid,softmax，交叉熵，反传  


Q：梯度截断  


Q：奥卡姆剃刀,什么时候必要  


Q：smooth l1为什么保留了l2的部分  


Q：优化器，优缺点  


Q：参数初始化方法，要解决的问题  


Q：python相关，列表与元组，列表去重（api和非api），深拷贝与浅拷贝，全局解释器，多线程  


Q：C/C++，指针和引用，指针的sizeof，char const *p和char* const p，new和malloc，判断struct字节数，stastic加到变量和函数上的作用，局部变量作用域，底层const具体含义  




Q：PCA和LDA和CCA  
PCA主成分分析：
找到最能代表这些样本的正交向量。使得原始数据在投影子空间的各个维度的方差最大  
（1）样本去中心化
（2）计算样本的协方差矩阵XX^{T}  
（3）对协方差矩阵做特征值分解
（4）取最大的d^{'} 个特征值所对应的特征向量
（5）计算投影矩阵  
LDA线性判别分析：  
投影后类内方差最小，类间方差最大。  
（1）计算类间散度矩阵Sb，Sb=(μ0−μ1)(μ0−μ1)T，其中μ0是第0类样本的均值，μ1是第1类样本的均值。
（2）计算类内散列矩阵Sw，Sw=∑x∈X0(x−μ0)(x−μ1)T+∑x∈X1(x−μ1)(x−μ1)T，其中X0是第0类样本的集合，X1是第1类样本的集合。
（3）求出最佳投影方向w，w即为S<-1>wSb的最大特征值所对应的特征向量。
（4）计算投影矩阵  
CCA典型相关分析：  
CCA将多维数据X,Y利用线性变换投影为1维的数据X′,Y′，然后计算X′,Y′的相关系数，进而得到二者的相关性。投影标准就是：投影后，两组数据的相关系数最大。  
常用作特征融合。即根据两组特征找到相关性最大的特征，这样可以利用较好的特征来从较差的特征中进行进一步的特征抽取，提高分类效果。  

PCA和LDA的相同点  
1都是经典的降维算法；
2都假设数据是符合高斯分布的；
3都利用了矩阵特征分解的思想。
PCA和LDA的不同点  
1PCA是无监督（训练样本无标签）的，LDA是有监督（训练样本有标签）的；
2PCA是去掉原始数据冗余的维度，LDA是选择一个最佳的投影方向，使得投影后相同类别的数据分布紧凑，不同类别的数据尽量相互远离。
3LDA最多可以降到k-1维（k是训练样本的类别数量，k-1是因为最后一维的均值可以由前面的k-1维的均值表示）；
4LDA可能会过拟合数据。  


Q：Gabor与LBP  
Gabor：Gabor 变换是一种加窗短时 Fourier 变换（简单理解起来就是在特定时间窗内做 Fourier 变换），是短时 Fourier 变换中当窗函数取为高斯函数时的一种特殊情况。因此，Gabor 滤波器可以在频域不同尺度、不同方向上提取相关的特征。另外 Gabor 函数与人眼的生物作用相仿，所以经常用作纹理识别上，并取得了较好的效果。在二维空间中，使用一个三角函数（如正弦函数）与一个高斯函数叠加，我们就得到了一个 Gabor 滤波器。  
LBP：局部二值模式。对每个像素点周边8个像素点，大于该像素值则为1，否则为0，每个像素点即可有一个8位01，对应数字0-255，即为LBP特征编码。一般将一幅图像的LBP特征谱的统计直方图作为分类识别的特征向量。  


Q：adaboost、SVM、LR  
adaboost：多次迭代，每次调整样本加权，最后把多个弱分类器加权合成最终的强分类器。损失是指数损失。  
LR,SVM：  
相同点  
1、LR和SVM都是分类算法 2、如果不考虑使用核函数，LR和SVM都是线性分类模型，也就是说它们的分类决策面是线性的。（其实LR也能使用核函数，但我们通常不会在LR中使用核函数，只会在SVM中使用（因为SVM核函数计算只用计算少数样本<支持向量>，LR核函数要计算所有样本，计算量巨大）。） 3、LR和SVM都是监督学习方法。 4、LR和SVM都是判别模型。（判别模型和生成模型的概念这里也不再赘述。典型的判别模型包括K近邻法、感知机、决策树、Logistic回归、最大熵、SVM、boosting、条件随机场等。典型的生成模型包括朴素贝叶斯法、隐马尔可夫模型、高斯混合模型。）  
不同点  
1、loss function不一样。LR基于概率理论，通过极大似然估计方法估计出参数的值，然后计算分类概率，取概率较大的作为分类结果。SVM基于几何间隔最大化，把最大几何间隔面作为最优分类面。 2、SVM只考虑分类面附近的局部的点，即支持向量，LR则考虑所有的点，与分类面距离较远的点对结果也起作用，虽然作用较小。（SVM中的分类面是由支持向量控制的，非支持向量对结果不会产生任何影响。LR中的分类面则是由全部样本共同决定。线性SVM不直接依赖于数据分布，分类平面不受一类点影响；LR则受所有数据点的影响，如果数据不同类别strongly unbalance，一般需要先对数据做balancing。） 3、在解决非线性分类问题时，SVM采用核函数，而LR通常不采用核函数。（分类模型的结果就是计算决策面，模型训练的过程就是决策面的计算过程。在计算决策面时，SVM算法中只有支持向量参与了核计算，即kernel machine的解的系数是稀疏的。在LR算法里，如果采用核函数，则每一个样本点都会参与核计算，这会带来很高的计算复杂度，所以，在具体应用中，LR很少采用核函数。） 4、SVM不具有伸缩不变性，LR则具有伸缩不变性。（SVM模型在各个维度进行不均匀伸缩后，最优解与原来不等价，对于这样的模型，除非本来各维数据的分布范围就比较接近，否则必须进行标准化，以免模型参数被分布范围较大或较小的数据影响。LR模型在各个维度进行不均匀伸缩后，最优解与原来等价，对于这样的模型，是否标准化理论上不会改变最优解。但是，由于实际求解往往使用迭代算法，如果目标函数的形状太“扁”，迭代算法可能收敛得很慢甚至不收敛。所以对于具有伸缩不变性的模型，最好也进行数据标准化。） 5、SVM损失函数自带正则项，因此，SVM是结构风险最小化算法。而LR需要额外在损失函数上加正则项。（所谓结构风险最小化，意思就是在训练误差和模型复杂度之间寻求平衡，防止过拟合，从而达到真实误差的最小化。未达到结构风险最小化的目的，最常用的方法就是添加正则项。）  


Q：色彩空间，直方图  
RGB：0-255  
HSV：色调（Hue,H），饱和度（Saturation,S），亮度（Value,V）  
YCbCr：视频图像和数字图像中常用的色彩空间。Y代表亮度，Cb和Cr代表蓝色分量和红色分量  
YUV：在现代彩色电视系统中，通常采用三管彩色摄像机或彩色CCD（点耦合器件）摄像机，它把摄得的彩色图像 信号，经分色、分别放大校正得到RGB，再经过矩阵变换电路得到亮度信号Y和两个色差信号R－Y、B－Y， 最后发送端将亮度和色差三个信号分别进行编码，用同一信道发送出去。这就是我们常用的YUV色彩空间。  
直方图均衡：把原始图像的灰度直方图从比较集中的某个灰度区间变成在全部灰度范围内的均匀分布。直方图均衡化就是对图像进行非线性拉伸，重新分配图像像素值，使一定灰度范围内的像素数量大致相同。  
计算每个灰度级别的像素数/总像素数  
计算每个灰度级的累计分布
新的灰度值为255x累计分布的概率  


Q：传统图像特征提取算法，包括霍夫检测，hog,sift细节（比如金字塔怎么产生），图像的梯度怎么求  
图像梯度求取：x方向左右像素差值，y方向上下像素差值，可获得每个像素点的梯度幅值和方向  
HOG特征：方向梯度直方图  
先转灰度，再计算每个像素点的梯度方向  
将图像划分成多个cell，获得每个cell内像素点的梯度直方图，直方图的bin（区间范围0-360/180）可以设定  
设定block（滑窗），串联一个block内包含的所有cell的梯度直方图  
把目标图像中所有block的梯度直方图串联即为整个目标的HOG特征  
比如，一个cell分9个角度区间，一个block分为4个cell，一个图像有7x8个block，那最后特征维度为9x4x7x8  
SIFT特征：尺度不变特征变换  
（1）构建尺度空间，检测极值点：  
尺度空间构建的基础是DOG金字塔，DOG金字塔构建的基础是高斯金字塔，首先构建高斯图像金字塔。  
将金字塔分成O组，每一组称为一个Octave；每一个Octave又分成S层，每层的图像是由不同方差的高斯滤波器滤波的结果；
每一个Octave的底层图像由上一个Octave的第S层图像高宽下2采样得到（缩小1/4）；
构建DOG图像金字塔：对高斯塔相邻两层做差得到DOG响应金字塔。在高斯金字塔中一共生成O组S层不同尺度的图像，合起来就构成了高斯金字塔的尺度空间，则给定的一组坐标（O,S）就可以唯一确定高斯金字塔中的一幅图像；
SIFT尺度空间的极值检测在DOG塔里进行，对每个点，比较其相邻的26个点（3x9-1），若为最大或最小值则记为待选极值点。  
（2）极值点过滤；  
以上极值点是在离散空间中搜索的(找的的极值点是在高斯差分之后所确定下来的，那么其是属于离散空间上的点，不一定是真正意义上的极值点。我们需用用到一条曲线来进行拟合。)。SIFT对每个待选点，通过插值得到极值点再连续空间中的精确位置（包括 行，列，尺度）；
令f(x)为该向量在DOG空间中的响应，将其泰勒展开，对f(X)求导，取其导数为0时候的点，即为所求精确位置距当前位置的偏移向量。当计算得到的偏移向量每一维都小于0.5时认为位置调整完毕。  
根据更新的极值点位置及偏移向量，计算对应的DOG响应（理论上f(X)的极值），如果该响应小于给定阈值（0.03），认为其不够稳定，删除。  
过滤可能的边缘点。SIFT认为边缘点不好定位，并且易受噪声影响，因此需要去除。注意到边缘点在横跨边缘的地方有较大曲率，而在垂直边缘的方向有较小曲率。曲率通过DOG响应的Hessian矩阵求得。  
（3）生成特征描述子：  
上一步中确定了每幅图中的特征点，为每个特征点计算一个方向，依照这个方向做进一步的计算， 利用关键点邻域像素的梯度方向分布特性为每个关键点指定方向参数，使算子具备旋转不变性。每个关键点有三个信息：位置，所处尺度、方向，由此可以确定一个SIFT特征区域。  
在实际计算时，我们在以关键点为中心的邻域窗口内采样，并用直方图统计邻域像素的梯度方向。梯度直方图的范围是0～360度，其中每45度一个柱，总共8个柱, 或者每10度一个柱，总共36个柱。直方图中的峰值就是主方向，其他的达到最大值80%的方向可作为辅助方向。
【每个关键点有三个信息：位置，所处尺度、方向，由此可以确定一个SIFT特征区域。在实际计算时，我们在以关键点为中心的邻域窗口内采样，并用直方图统计邻域像素的梯度方向。直方图中的峰值就是主方向，其他的达到最大值80%的方向可作为辅助方向。将坐标轴旋转为关键点的方向，以确保旋转不变性。在每4×4的小块上计算8个（360/45）方向的梯度方向直方图，绘制每个梯度方向的累加值，即可形成一个种子点，计算keypoint周围的16x16的window中每一个像素的梯度，而且使用高斯下降函数降低远离中心的权重。这样就可以对每个feature形成一个4x4x8=128维的描述子，每一维都可以表示4x4个格子中一个的scale/orientation. 将这个向量归一化之后，就进一步去除了光照的影响。】放弃吧。。  
霍夫检测：坐标系转换，笛卡尔转到极坐标系  


Q：过拟合、梯度爆炸  
过拟合：正则，dropout，BN，早停，数据增强  
爆炸：正则，梯度截断，relu  
消失：BN，relu，残差  

Q：参数量、计算量  
对于输出特征图上的每一个位置  
参数量：普通卷积 KxKxC1xC2 深度可分 KxKxC1+1x1xC1xC2  
计算量：（C1xKxK + C1xKxK-1）x H x W x C2  
括号里第一项是乘法运算数，第二项是加法运算数，因为n个数相加，要加n-1次，括号里即一次卷积运算数  
不考虑bias，会有一个-1，如果考虑bias，就没有 -1  
不考虑加法那直接第二项不要了  







