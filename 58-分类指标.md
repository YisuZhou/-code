【混淆矩阵---确定截断点后，评价学习器性能】  
从混淆矩阵中可以获得很多信息  
TP（实际为正预测为正），FP（实际为负但预测为正），TN（实际为负预测为负），FN（实际为正但预测为负）  
查全率（召回率，recall）：样本中的正例有多少被预测准确了，衡量的是查全率，预测对的正例数占真正的正例数的比率：  
R＝ 预测出的并且是对的 / 所有本来应该预测出的 = TP / (TP+FN)  
查准率（精准率，Precision）：针对预测结果而言，预测为正的样本有多少是真正的正样本，衡量的是查准率，预测正确的正例数占预测为正例总量的比率：
P＝预测出的并且对的 / 所有预测出的 = TP / (TP+FP)  
准确率：反映分类器统对整个样本的判定能力，能将正的判定为正，负的判定为负的能力：  
Accuracy=(TP+TN) / (TP+FP+TN+FN)  
查准率和查全率通常是一对矛盾的度量，通常一个高，另外一个就低。两个指标都很重要，我们一般用两种方法综合考虑两个指标：  
（1）查准率=查全率的点，过了这个点，查全率将增加，查准率将降低。  
（2）F1 score，（1+beta^2）PR / beta^2 P+R  
  
【PR曲线】  
P-R曲线的P就是查准率（Precision），R就是查全率（Recall）。以P作为横坐标，R作为纵坐标，就可以画出P-R曲线。  
对于同一个模型，通过调整分类阈值，可以得到不同的P-R值，从而可以得到一条曲线（纵坐标为P，横坐标为R）。  
通常随着分类阈值从大到小变化（大于阈值认为P），Precision减小，Recall增加。  
比较两个分类器好坏时，显然是查得又准又全的比较好，也就是的PR曲线越往坐标（1，1）的位置靠近越好。  
若一个学习器的P-R曲线被另一个学习器完全”包住”，则后者的性能优于前者。  
当存在交叉时，可以计算曲线围住面积，不太容易判断，但是可以通过平衡点（查准率=查全率，Break-Even Point，BEP）来判断。  
  
【ROC曲线， AUC ----评价学习器性能，检验分类器对客户进行正确排序的能力】  
观察这个学习器利用所有可能的截断点（就是所有样本的预测结果）对样本进行分类时的效果，注意要先对所有可能的截断点进行排序，方便对比观察。  
ROC曲线描绘的是不同的截断点时，并以FPR和TPR为横纵坐标轴，描述随着截断点的变小，TPR随着FPR的变化。  
纵轴：TPR=正例分对的概率 = TP/(TP+FN)，其实就是Recall  
横轴：FPR=负例分错的概率 = FP/(FP+TN)，预测出来但是错的 / 所有负例  
ROC曲线越向上凸起，说明用了这个学习器在很小的代价（负例分错为正例，横轴）下达到了相对较大的查全率（TPR）。  
作图步骤：  
1. 根据学习器的预测结果（注意，是正例的概率值，非0/1变量）对样本进行排序（从大到小）-----这就是截断点依次选取的顺序  
2. 按顺序选取截断点，并计算TPR和FPR---也可以只选取n个截断点，分别在1/n，2/n，3/n等位置  
3. 连接所有的点（TPR，FPR）即为ROC图  
如果一个完全包住了另一个，那很明显，否则利用ROC曲线下的面积（AUC，area under ROC curve，是一个数值)进行比较  
  
【PR和ROC对比】  
与PR曲线相比，相对来讲ROC曲线会更稳定，在正负样本量都足够的情况下，ROC曲线足够反映模型的判断能力。  
而在正负样本分布得极不均匀(highly skewed datasets)的情况下（正样本极少），PRC比ROC能更有效地反映分类器对于整体分类情况的好坏。  
总之，只画一个曲线时，如果没有data imbalance,倾向于用ROC（更简洁，更好理解）。如果数据样本不均衡,分两种情况：  
情况1：如正样本远小于负样本，PR更敏感，因为用到了precision=(TP/(TP+FP))。  
情况2：正样本远大于负样本，PR和ROC差别不大，都不敏感。  
对于同一模型，PR和ROC曲线都可以说明一定的问题，而且二者有一定的相关性，如果想评测模型效果，也可以把两条曲线都画出来综合评价。  
  
【PR计算】  
我记得好像有两种插值标准？？
  
